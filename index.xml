<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Eleven</title>
    <link>http://veh47.github.io/</link>
    <description>Recent content on Eleven</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Mon, 20 Jan 2020 16:32:26 +0800</lastBuildDate>
    
        <atom:link href="http://veh47.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Prometheus Operator 自定义发现</title>
      <link>http://veh47.github.io/post/prometheus-operaotr%E8%87%AA%E5%8A%A8%E5%8F%91%E7%8E%B0/</link>
      <pubDate>Mon, 20 Jan 2020 16:32:26 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/prometheus-operaotr%E8%87%AA%E5%8A%A8%E5%8F%91%E7%8E%B0/</guid>
      
        <description>我们在之前的文章中写了prometheus-operator的自定义监控 自定义告警. 但是假如集群中有几十个或几百个service/pod, 如</description>
      
    </item>
    
    <item>
      <title>Ingress Nginx部署</title>
      <link>http://veh47.github.io/post/ingress-nginx%E9%83%A8%E7%BD%B2/</link>
      <pubDate>Thu, 16 Jan 2020 13:48:39 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/ingress-nginx%E9%83%A8%E7%BD%B2/</guid>
      
        <description>nginx-ingress 和 traefik 都是比如热门的 ingress-controller，作为反向代理将外部流量导入集群内部，将 Kubernetes 内部的 Service 暴露给外部，在 Ingress 对象中通过域名匹配</description>
      
    </item>
    
    <item>
      <title>NFS持久化存储</title>
      <link>http://veh47.github.io/post/nfs%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8/</link>
      <pubDate>Thu, 09 Jan 2020 23:40:27 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/nfs%E6%8C%81%E4%B9%85%E5%8C%96%E5%AD%98%E5%82%A8/</guid>
      
        <description>平时我们使用的一些pod都是无状态服务, 但是在生产环境中免不了一些有状态服务, 比如数据库之类的,就需要有专门的挂载存储保障数据的安全 PV 的全称</description>
      
    </item>
    
    <item>
      <title>自定义监控etcd</title>
      <link>http://veh47.github.io/post/%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%91%E6%8E%A7etcd/</link>
      <pubDate>Thu, 09 Jan 2020 23:37:01 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/%E8%87%AA%E5%AE%9A%E4%B9%89%E7%9B%91%E6%8E%A7etcd/</guid>
      
        <description>在Prometheus-operator部署好以后, 原生的grafana上有许多自己模板对集群当中的各类资源进行监控, 但是这些监控模板并不全</description>
      
    </item>
    
    <item>
      <title>Prometheus Operator部署</title>
      <link>http://veh47.github.io/post/prometheus-operator%E9%83%A8%E7%BD%B2/</link>
      <pubDate>Thu, 09 Jan 2020 23:34:50 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/prometheus-operator%E9%83%A8%E7%BD%B2/</guid>
      
        <description>集群完成了, 得有一个工具把所有的资源监控起来, 手动去创建监控对于很多小白来说简直就是折磨, 各种坑, 所以很幸运的时现在有很多的全家桶, 直接上手</description>
      
    </item>
    
    <item>
      <title>Dashboard部署</title>
      <link>http://veh47.github.io/post/dashboard%E9%83%A8%E7%BD%B2/</link>
      <pubDate>Thu, 09 Jan 2020 23:31:32 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/dashboard%E9%83%A8%E7%BD%B2/</guid>
      
        <description>dashboard 是kubernetes的原生展示页面, 偶尔看看就可以, 不必真的去管理 以下文件分为三部分, 分别是dashboard.yaml文件, admin</description>
      
    </item>
    
    <item>
      <title>全新一台node节点加入集群</title>
      <link>http://veh47.github.io/post/%E5%85%A8%E6%96%B0%E4%B8%80%E5%8F%B0node%E8%8A%82%E7%82%B9%E5%8A%A0%E5%85%A5%E9%9B%86%E7%BE%A4/</link>
      <pubDate>Thu, 09 Jan 2020 22:55:01 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/%E5%85%A8%E6%96%B0%E4%B8%80%E5%8F%B0node%E8%8A%82%E7%82%B9%E5%8A%A0%E5%85%A5%E9%9B%86%E7%BE%A4/</guid>
      
        <description>基于前面的所有文章完成后，在实际工作中面对很多业务的突然扩大, 流量的增加, 存储, 媒体 服务 等等一系列的增加, 这时候原先的node节点就不够用,</description>
      
    </item>
    
    <item>
      <title>CoreDNS安装验证</title>
      <link>http://veh47.github.io/post/coredns%E5%AE%89%E8%A3%85%E9%AA%8C%E8%AF%81/</link>
      <pubDate>Thu, 09 Jan 2020 22:49:56 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/coredns%E5%AE%89%E8%A3%85%E9%AA%8C%E8%AF%81/</guid>
      
        <description>叙述 截止到目前为止，整个集群的核心组件已经安装完成。 此时集群内部还需要 CoreDNS 组件的支持。 coredns已经成为默认dns了。之前是kube-dn</description>
      
    </item>
    
    <item>
      <title>Kube Proxy组件部署</title>
      <link>http://veh47.github.io/post/kube-proxy%E7%BB%84%E4%BB%B6%E9%83%A8%E7%BD%B2/</link>
      <pubDate>Thu, 09 Jan 2020 22:46:22 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/kube-proxy%E7%BB%84%E4%BB%B6%E9%83%A8%E7%BD%B2/</guid>
      
        <description>kube-proxy运行在所有节点上，它监听apiserver中service和endpoint的变化情况，创建路由规则提供服务IP和负载均</description>
      
    </item>
    
    <item>
      <title>Kubelet组件安装</title>
      <link>http://veh47.github.io/post/kubelet%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85/</link>
      <pubDate>Thu, 09 Jan 2020 22:35:33 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/kubelet%E7%BB%84%E4%BB%B6%E5%AE%89%E8%A3%85/</guid>
      
        <description>kubelet运行在每个worker节点上，接收kube-apiserver发送的请求，管理Pod容器，执行交互命令, 如果你的master节</description>
      
    </item>
    
    <item>
      <title>Docker安装</title>
      <link>http://veh47.github.io/post/docker%E5%AE%89%E8%A3%85/</link>
      <pubDate>Thu, 09 Jan 2020 22:31:41 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/docker%E5%AE%89%E8%A3%85/</guid>
      
        <description>正常操作到这里，k8s 的 master 集群已经安装完成，只需要添加node节点就可以了; 但也要把 master 节点都要通过 work 节点的组件，加入到master集群中； kubernetes</description>
      
    </item>
    
    <item>
      <title>网络组件flannel安装</title>
      <link>http://veh47.github.io/post/%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6flannel%E5%AE%89%E8%A3%85/</link>
      <pubDate>Thu, 09 Jan 2020 22:26:49 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/%E7%BD%91%E7%BB%9C%E7%BB%84%E4%BB%B6flannel%E5%AE%89%E8%A3%85/</guid>
      
        <description>Kubernetes要求集群内各个节点(包括master)能通过Pod网段互联互通，Flannel使用vxlan技术为各个节点创建一个互通的</description>
      
    </item>
    
    <item>
      <title>部署高可用schduler</title>
      <link>http://veh47.github.io/post/%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8schduler/</link>
      <pubDate>Thu, 09 Jan 2020 22:21:37 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/%E9%83%A8%E7%BD%B2%E9%AB%98%E5%8F%AF%E7%94%A8schduler/</guid>
      
        <description>scheduler 的作用 将待调度的 POD (API 新创建的 POD, Controller manager 为补足副本而创建的 POD 等) 按照特定的调度算法和调度策略绑定(Binding) 到集群中某个合适的NODE, 上</description>
      
    </item>
    
    <item>
      <title>部署kube Controller Manager高可用</title>
      <link>http://veh47.github.io/post/%E9%83%A8%E7%BD%B2kube-controller-manager%E9%AB%98%E5%8F%AF%E7%94%A8/</link>
      <pubDate>Thu, 09 Jan 2020 22:11:58 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/%E9%83%A8%E7%BD%B2kube-controller-manager%E9%AB%98%E5%8F%AF%E7%94%A8/</guid>
      
        <description>该集群包含三个节点，启动后通过竞争选举机制产生一个leader节点，其他节点为阻塞状态。当leader节点不可用时， 阻塞节点将会在此选举产生</description>
      
    </item>
    
    <item>
      <title>测试访问apiserver状态</title>
      <link>http://veh47.github.io/post/%E6%B5%8B%E8%AF%95%E8%AE%BF%E9%97%AEapiserver%E7%8A%B6%E6%80%81/</link>
      <pubDate>Thu, 09 Jan 2020 22:04:59 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/%E6%B5%8B%E8%AF%95%E8%AE%BF%E9%97%AEapiserver%E7%8A%B6%E6%80%81/</guid>
      
        <description>到这里，ETCD集群、kube-nginx + keepalived、kube-apiserver都已经安装完成。 此时可以测试一下前面安装的是否</description>
      
    </item>
    
    <item>
      <title>Kube Apiserver集群服务安装</title>
      <link>http://veh47.github.io/post/kube-apiserver%E9%9B%86%E7%BE%A4%E6%9C%8D%E5%8A%A1%E5%AE%89%E8%A3%85/</link>
      <pubDate>Thu, 09 Jan 2020 18:26:42 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/kube-apiserver%E9%9B%86%E7%BE%A4%E6%9C%8D%E5%8A%A1%E5%AE%89%E8%A3%85/</guid>
      
        <description>k8s API Server提供了k8s各类资源对象（pod,RC,Service等）的增删改查及watch等HTTP Rest接口，是整个系统的数据总线</description>
      
    </item>
    
    <item>
      <title>Kube Nginx和keepalived部署安装</title>
      <link>http://veh47.github.io/post/kube-nginx%E5%92%8Ckeepalived%E9%83%A8%E7%BD%B2%E5%AE%89%E8%A3%85/</link>
      <pubDate>Thu, 09 Jan 2020 18:15:29 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/kube-nginx%E5%92%8Ckeepalived%E9%83%A8%E7%BD%B2%E5%AE%89%E8%A3%85/</guid>
      
        <description>本集群使用 nginx + keepalived 实现高可用, 使用四层转发, 可以把apiserver schduler controller-manager都能做到高可用, 不至于apiserv</description>
      
    </item>
    
    <item>
      <title>Kubernetes Master节点部署介绍和前置工作</title>
      <link>http://veh47.github.io/post/kubernetes-master%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2%E4%BB%8B%E7%BB%8D%E5%92%8C%E5%89%8D%E7%BD%AE%E5%B7%A5%E4%BD%9C/</link>
      <pubDate>Thu, 09 Jan 2020 18:09:41 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/kubernetes-master%E8%8A%82%E7%82%B9%E9%83%A8%E7%BD%B2%E4%BB%8B%E7%BB%8D%E5%92%8C%E5%89%8D%E7%BD%AE%E5%B7%A5%E4%BD%9C/</guid>
      
        <description>到这里你的etcd基本创建完成, 接下来就该master节点部署 组件介绍 kubernetes master节点运行组件如下: kube-apiserver、kube</description>
      
    </item>
    
    <item>
      <title>Kubernetes ETCD集群部署</title>
      <link>http://veh47.github.io/post/kubernetes-etcd%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</link>
      <pubDate>Thu, 09 Jan 2020 17:37:07 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/kubernetes-etcd%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/</guid>
      
        <description>etcd在整个集群中担任数据库的角色, 所以一般都使用高可用, 这里使用三台, 也就是三台master节点 下载和分发etcd二进制文件 创建etcd</description>
      
    </item>
    
    <item>
      <title>Kubernetes部署前期准备工作</title>
      <link>http://veh47.github.io/post/kubernetes%E9%83%A8%E7%BD%B2%E5%89%8D%E6%9C%9F%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C/</link>
      <pubDate>Thu, 09 Jan 2020 17:23:57 +0800</pubDate>
      
      <guid>http://veh47.github.io/post/kubernetes%E9%83%A8%E7%BD%B2%E5%89%8D%E6%9C%9F%E5%87%86%E5%A4%87%E5%B7%A5%E4%BD%9C/</guid>
      
        <description>上一篇文章基本把环境准备好了, 这些该做一些前期的准备工作, 再说一次别照抄,自己看着想着,细心点 不然自己找坑 安装cfssl工具集 本文章使用Cl</description>
      
    </item>
    
  </channel>
</rss>
